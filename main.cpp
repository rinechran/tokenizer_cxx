#include "tokenizer_cxx.h"
#include <iostream>
#include <string>

int main() {
    auto tokenizer = make_tokenizer("tokenizer.json");

    std::string input = "ì•ˆë…•í•˜ì„¸ìš”!!! ã…ã„´ã…‡ã…ã„´ã…‡ã…ã„´ã…‡ asdas hell world";
    auto result = tokenizer->encode(input, true);

    std::cout << "âœ… Token IDs: ";
    for (auto id : result.ids)
        std::cout << id << " ";
    std::cout << "\n";

    std::cout << "âœ… Tokens: ";
    for (auto token : result.tokens)
        std::cout << token.c_str() << " ";
    std::cout << "\n";

    std::cout << "ðŸŽ¯ Attention Mask: ";
    for (auto mask : result.attention_mask)
        std::cout << mask << " ";
    std::cout << "\n";

    std::string decoded = tokenizer->decode(result.ids, true)
        .c_str();
    std::cout << "ðŸ” Decoded Text: " << decoded << "\n";

    return 0;
}
