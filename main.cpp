#include "tokenizer_cxx.h"
#include <iostream>
#include <string>

int main() {
    auto tokenizer = make_tokenizer("tokenizer.json");

    std::string input = "ì•ˆë…•í•˜ì„¸ìš”!!! ã…ã„´ã…‡ã…ã„´ã…‡ã…ã„´ã…‡ asdas hell world";
    auto result = tokenizer->encode(input);

    std::cout << "âœ… Token IDs: ";
    for (auto id : result.ids)
        std::cout << id << " ";
    std::cout << "\n";

    std::cout << "âœ… Token : ";
    for (auto tokens : result.tokens)
        std::cout << tokens.c_str() << " ";

    std::cout << "ðŸŽ¯ Attention Mask: ";
    for (auto mask : result.attention_mask)
        std::cout << mask << " ";
    std::cout << "\n";

    return 0;
}
